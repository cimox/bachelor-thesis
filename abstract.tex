%!TEX root = ./main.tex

% This file is part of the i10 thesis template developed and used by the
% Media Computing Group at RWTH Aachen University.
% The current version of this template can be obtained at
% <http://www.media.informatik.rwth-aachen.de/karrer.html>.

\loadgeometry{myAbstract}
\chapter*{Anotácia\markboth{Abstrakt}{Abstrakt}}
%\addcontentsline{toc}{chapter}{\protect\numberline{}Abstrakt}
\label{abstrakt}
\begin{center}
\textbf{Fakulta Informatiky a Informačných Technológií}\\
\textbf{Slovenská Technická Univerzita}\\
\end{center}
\begin{tabular}{ p{15em} p{15em} }
Meno: & Matúš Cimerman\\
Vedúci bakalárskej práce: & Ing. Jakub Ševcech\\
Bakalárska práca: & Analýza prúdu údajov\\
Študijný program: & Informatika\\
Máj 2015
\end{tabular}

%slovak version
V súčastnosti pozorujeme spracovanie a analýzu veľkých objemov dát (angl. Big Data) v mnohých oblastiach. Rastúci objem, rôznorodosť a rýchlosť dát zvyšuje záujem o Big Data. Najviac oblasti, v ktorých je veľmi dôležité spracovať veľký objem prúdiacich údajov sú napríklad dáta zo senzorov, počítačové siete, či sociálne médiá ako napríklad Twitter. Tieto potencionálne nekonečné zdroje dát, ktoré sú generované prudko meniacou rýchlosťou a objemom, sú jednoducho nazývané \textit{prúdy údajov}. Spracovanie a analýza prúdu údajov je komplexná úloha. Riešenie musí poskytnúť nízku odozvu, odolnosť voči chybám a horizontálnu škálovateľnosť.
V práci budujeme softvérovú súčiastku na spracovanie prúdov v takmer reálnom čase. Poskytuje hodnotné výstupy na základe používateľských dopytov do prúdu, ktorý je citlivý na okamžité spracovanie. Bežne používaný spôsob spracovania Big Data je dávkové spracovanie s použitím MapReduce modelu. 
Kvôli povahe 
%(nekonečný prúd údajov, veľký objem, rýchlosť, atď) 
prúdu údajov je tento prístup v podstate nepoužiteľný na to, aby sme zabezpečili požiadavku získať filtrované alebo analyzované výstupy v takmer reálnom čase. Na dosiahnutie týchto požiadaviek musíme použiť iný prístup nazývaný jednoducho \textit{prúdové spracovanie}. Paradigmy na prúdové spracovanie predstavujú napr. dátovody a filtre.
V našom projekte sme analyzovali existujúce riešenia a programovacie rámce na spracovanie dátových tokov. Poskytujeme overenie výkonnosti našeho riešenia. Navrhované riešenie je určené na spracovanie dátových tokov veľkého objemu, je škálovateľné a odolné voči chybám. Splnili sme požiadavku na spracovanie v takmer-reálnom čase použitím našeho riešenia a inkrementálnych algoritmov.

%OLD VERSION
%Dnes sa stretávame so spracovaním a analýzou veľkého objemu dát (angl. Big Data) v mnohých oblastiach. S narastajúcim objemom dát rastie aj záujem o túto problematiku. Toto sa najviac dotýka oblastí kde je potrebné spracovávať dáta zo senzorov, sietí telekomunikačných operátorov, ale tiež sociálnych medií ako napríklad Twitter. Dáta z týchto zdrojov prúdia v obrovských množstvách, pričom sa v čase rýchlo menia, takéto prúdy nazývame jednoducho prúd dát. Tieto prúdy sú potenciálne nekonečné. Prúdy dát chceme spracovať a analyzovať v reálnom čase, aby sme mohli ponúknuť používateľom hodnotný výstup s čo najmenšou odozvou. Najčastejší spôsob spracovania dát je dávkové spracovanie s použítím MapReduce modelu, čo však nie je aplikovateľné pri viacerých úlohách spracovania dát. Táto metóda, ale nespĺňa naše požiadavky na spracovanie dát v reálnom čase. Na dosiahnutie našej požiadavky potrebujeme iný prístup, ktorý nazývame spracovanie prúdu dát. Jedna z paradigiem na spracovanie prúdu dát je napríklad, dátovody a filtre.
%Spracovanie a analýza veľkých prúdov dát je komplexný problém, pretože prúd musí byť spracovaný s nízkou odozvou, riešenie musí byť odolné proti chybám a  horizontálne škálovateľné. V našej práci budeme analyzovať existujúce riešenia a rámce na analýzu prúdu dát. Poskytujeme overenie charakteristík týchto riešení v roznych problémoch, ktoré si vyžadujú spracovanie prúdu dát v reálnom čase. Na základe tohto navrhujeme a implementujeme aplikáciu, ktorá spracuje a analyzuje veľký prúd dát (napríklad prúd dát Twittru), ktorá umožní používateľom získať hodnotný výstup, ktorý sa mení v reálnom čase.\\
\emptydoublepage


\chapter*{Annotation\markboth{Abstract}{Abstract}}
%\addcontentsline{toc}{chapter}{\protect\numberline{}Abstract}
\label{abstract}
\begin{center}
\textbf{Faculty of Informatics and Information Technology}\\
\textbf{Slovak University of Technology}\\
\end{center}
\begin{tabular}{ p{10em} p{15em} }
Name: & Matúš Cimerman\\
Supervisor: & Ing. Jakub Ševcech\\
Bachelor thesis: & Data stream analysis\\
Course: & Informatics\\
2015, May
\end{tabular}

%english version
Nowadays we can see Big Data processing and analysis in many domains. Increasing volume, variety and velocity of data has initiated growing interest in Big Data. There are most affected domains where it is essential to process large amounts of streaming data, for example data produced from sensors in general, computer networks or social media such as Twitter. These potentially infinite sources of data, which generating data in rapidly changing velocity and volume, are simply called \textit{data streams}. Processing and analysis of data streams is a complex issue, stream needs to be processed with low-latency, a solution must be fault-tolerant and horizontally scalable.We are building software component to process data streams with near real-time latency. It is providing valuable outputs based on user queries over data stream, which are sensitive to near real-time processing. Routinely used method of Big Data processing is batch processing using MapReduce model. This approach is basically not applicable to process data streams because of the characteristics 
%(infinite flowing streams, high volume, velocity, etc.) 
and requirements to gain filtered or analyzed outputs in near real-time. To achieve these requirements, we need use different approach essentialy called data \textit{stream processing}. One of paradigms to process data streams is for example, pipelines and filters.In our project, we analyzed existing solutions and frameworks for processing data streams. We provide performance verification of the our solution. Proposed solution is designed to process high-volume data streams, its highly scalable and fault-tolerant. We achieved requirement to process data streams in near real-time using proposed topology and incremental algorithms.

%OLD VERSION
%Nowadays we can see Big Data processing and analysis in many domains. With increasing volume of data also growing up interest in this issue. The most affected domains where it is necessary to process data from sensors, networks, telecommunications operators, but also social media such as Twitter. Data from these sources flow in large amounts, while they are rapidly changing, these streams are simply called data streams. These streams are potentially infinite.
%We want to process and analyze data streams in real-time, to provide users valuable outputs with minimal latency. The most common method of data processing is batch processing using MapReduce model, which is not applicable in variety of data processing tasks. This method is not meeting our requirements to process data streams in real-time. To achieve these requirements, we need use different approach called data stream processing. One of paradigms to process data streams is for example, pipes and filters.
%Processing and analysis of big data streams is a complex issue, because stream needs to be processed with low-latency, the solution must be fault-tolerant and horizontally scalable. In our project, we will analyze existing solutions and frameworks for analyzing data stream. We provide verification of the characteristics of these solutions in various problems, that require data stream processing in real time. Based on this, we propose and implement a application, which processing and analyzing big data streams (e.g. Twitter data stream) and allows users to get valuable outputs in real-time.\\
\emptydoublepage
\loadgeometry{myText}
